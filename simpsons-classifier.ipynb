{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "67cb315f",
   "metadata": {},
   "source": [
    "# 🧠 Simpsons Character Classifier\n",
    "\n",
    "This notebook implements a deep learning-based image classification model that can identify characters from *The Simpsons* using a Convolutional Neural Network (CNN). It uses the top 10 characters from the official Kaggle dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ce46640",
   "metadata": {},
   "source": [
    "## 📁 1. Dataset and Setup\n",
    "\n",
    "We begin by setting up the image size, reading the dataset, and filtering the top 10 characters with the most images."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80d27394",
   "metadata": {},
   "source": [
    "## 🧼 2. Preprocessing\n",
    "\n",
    "Images are normalized, reshaped, and labels are one-hot encoded. We also split the dataset into training and validation sets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "805a6555",
   "metadata": {},
   "source": [
    "## 🧱 3. Model Architecture\n",
    "\n",
    "We define a multi-layer CNN with increasing depth, max-pooling, dropout, and a final softmax layer for 10-class prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b58db1fd",
   "metadata": {},
   "source": [
    "## 🏋️ 4. Training the Model\n",
    "\n",
    "We compile the model with SGD, use a custom learning rate schedule, and train it for 10 epochs using a data generator."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e07dacd0",
   "metadata": {},
   "source": [
    "## 🧪 5. Testing and Predictions\n",
    "\n",
    "We test the trained model on a sample image and visualize the predicted result."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95a4dc13",
   "metadata": {},
   "source": [
    "## ✅ Conclusion\n",
    "\n",
    "This model demonstrates effective character recognition from images using CNNs. You can further expand it to include more characters, add GUI for predictions, or deploy using Streamlit/Flask."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c1ea565",
   "metadata": {},
   "source": [
    "!pip install caer canaro"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "103ca79a",
   "metadata": {},
   "source": [
    "import os\n",
    "import caer\n",
    "import canaro\n",
    "import numpy as np\n",
    "import cv2 as cv\n",
    "import gc\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Dropout, Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.optimizers import SGD"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a040d2f",
   "metadata": {},
   "source": [
    "IMG_SIZE = (80,80)\n",
    "channels = 1\n",
    "char_path = r'/kaggle/input/the-simpsons-characters-dataset/simpsons_dataset'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d52d1b3f",
   "metadata": {},
   "source": [
    "char_dict = {}\n",
    "for char in os.listdir(char_path):\n",
    "    char_dict[char] = len(os.listdir(os.path.join(char_path, char)))\n",
    "#grab all the folders in the path and find no. of images in them\n",
    "\n",
    "char_dict = caer.sort_dict(char_dict, descending = True)\n",
    "char_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f250d29",
   "metadata": {},
   "source": [
    "#now adding characters\n",
    "characters = []\n",
    "count = 0\n",
    "for i in char_dict:\n",
    "    characters.append(i[0])\n",
    "    count += 1\n",
    "    if count >= 10:\n",
    "        break\n",
    "characters\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "211c5170",
   "metadata": {},
   "source": [
    "#training data\n",
    "train = caer.preprocess_from_dir(char_path, characters, channels = channels, IMG_SIZE=IMG_SIZE, isShuffle = True)\n",
    "len(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0a3b733",
   "metadata": {},
   "source": [
    "featureSet, labels = caer.sep_train(train, IMG_SIZE = IMG_SIZE)\n",
    "#Seperate training set into features and labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "712c767e",
   "metadata": {},
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "#to_categorical is used to convert class labels (integers) into one-hot encoded vectors.\n",
    "#normalize the featureset (0,1)\n",
    "featureSet = caer.normalize(featureSet)\n",
    "labels = to_categorical(labels, len(characters))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09a1b688",
   "metadata": {},
   "source": [
    "x_train, x_val, y_train, y_val = caer.train_val_split(featureSet, labels, val_ratio = .2 )\n",
    "#20 percent goes to validation set and 80 percent goes to the training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ace155d",
   "metadata": {},
   "source": [
    "del train\n",
    "del featureSet\n",
    "del labels\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44d95d55",
   "metadata": {},
   "source": [
    "BATCH_SIZE = 32\n",
    "EPOCHS = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbff2584",
   "metadata": {},
   "source": [
    "#image data generator\n",
    "datagen = canaro.generators.imageDataGenerator()\n",
    "train_gen = datagen.flow(x_train, y_train, batch_size = 32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cb846d2",
   "metadata": {},
   "source": [
    "#creating the model\n",
    "w, h = IMG_SIZE[:2]\n",
    "\n",
    "output_dim = 10\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=(w, h,channels)))\n",
    "model.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), padding='same', activation='relu'))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Conv2D(256, (3, 3), padding='same', activation='relu')) \n",
    "model.add(Conv2D(256, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "\n",
    "# Output Layer\n",
    "model.add(Dense(output_dim, activation='softmax'))\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85cf56b4",
   "metadata": {},
   "source": [
    "# Training the model\n",
    "optimizer = SGD(learning_rate=0.001, decay=1e-7, momentum=0.9, nesterov=True)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "callbacks_list = [LearningRateScheduler(canaro.lr_schedule)]\n",
    "\n",
    "training = model.fit(train_gen,\n",
    "                    steps_per_epoch = len(x_train) // BATCH_SIZE, epochs = EPOCHS,\n",
    "                    validation_data = (x_val, y_val), validation_steps = len(y_val) // BATCH_SIZE,\n",
    "                    callbacks = callbacks_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0e4172b",
   "metadata": {},
   "source": [
    "#testing\n",
    "test_path = r'/kaggle/input/the-simpsons-characters-dataset/kaggle_simpson_testset/kaggle_simpson_testset/milhouse_van_houten_15.jpg'\n",
    "\n",
    "img = cv.imread(test_path)\n",
    "\n",
    "plt.imshow(img)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "def prepare(img):\n",
    "    img = cv.cvtColor(img,cv.COLOR_BGR2GRAY)\n",
    "    img = cv.resize(img, IMG_SIZE)\n",
    "    img = caer.reshape(img, IMG_SIZE, 1)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af383f0f",
   "metadata": {},
   "source": [
    "predictions = model.predict(prepare(img))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01845acb",
   "metadata": {},
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4273280e",
   "metadata": {},
   "source": [
    "# Getting class with the highest probability\n",
    "print(characters[np.argmax(predictions[0])])"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 1408,
     "sourceId": 27569,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31041,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
